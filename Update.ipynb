{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pickle, os\n",
    "\n",
    "os.environ['DATABASE_TABLE_NAME'] = 'product-table-dev-manual'\n",
    "os.environ['REGION'] = 'ap-southeast-1'\n",
    "os.environ['INVENTORY_BUCKET_NAME'] = 'product-bucket-dev-manual'\n",
    "os.environ['INPUT_BUCKET_NAME'] = 'input-product-bucket-dev-manual'\n",
    "os.environ['DAX_ENDPOINT'] = 'longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111'\n",
    "os.environ['LINEKEY'] = '2uAfV4AoYglUGmKTAk2xNOm0aV2Ufgh1BQPvQl9vJd4'\n",
    "REGION = 'ap-southeast-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update\n",
    "update the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from s3bz.s3bz import S3\n",
    "from nicHelper.wrappers import add_method, add_class_method, add_static_method\n",
    "from nicHelper.dictUtil import stripDict, printDict, hashDict, saveStringToFile, loadStringFromFile, saveDictToFile, loadDictFromFile\n",
    "from nicHelper.exception import errorString\n",
    "from dict_hash import dict_hash, sha256\n",
    "from base64 import b64encode, b64decode\n",
    "from dataclasses_json import dataclass_json, Undefined, CatchAll\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import os, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from villaProductDatabase.database import ProductDatabase\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import os\n",
    "DBHASHLOCATION = '/tmp/database.hash'\n",
    "DBCACHELOCATION = '/tmp/database.cache'\n",
    "DATABASE_TABLE_NAME = os.environ.get('DATABASE_TABLE_NAME')\n",
    "INVENTORY_BUCKET_NAME = os.environ.get('INVENTORY_BUCKET_NAME')\n",
    "INPUT_BUCKET_NAME = os.environ.get('INPUT_BUCKET_NAME')\n",
    "REGION = os.environ.get('REGION') or 'ap-southeast-1'\n",
    "ACCESS_KEY_ID = os.environ.get('USER') or None\n",
    "SECRET_ACCESS_KEY = os.environ.get('PW') or None\n",
    "LINEKEY= os.environ.get('LINEKEY')\n",
    "  \n",
    "try:\n",
    "  DAX_ENDPOINT = os.environ['DAX_ENDPOINT']\n",
    "  print(DAX_ENDPOINT)\n",
    "except KeyError as e:\n",
    "  print(f'dax endpoint missing {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Updater:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester( Updater, ProductDatabase):\n",
    "  class Meta:\n",
    "    table_name = os.environ['DATABASE_TABLE_NAME']\n",
    "    region = os.environ['REGION']\n",
    "    billing_mode='PAY_PER_REQUEST'\n",
    "    dax_read_endpoints = [DAX_ENDPOINT] if DAX_ENDPOINT else None\n",
    "    dax_write_endpoints = [DAX_ENDPOINT] if DAX_ENDPOINT else None\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update with dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@add_class_method(Updater)\n",
    "def updateWithDict(cls, originalObject:Updater, inputDict:dict ):\n",
    "  data = originalObject.data\n",
    "  data.update(inputDict)\n",
    "  return cls.fromDict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engname is JOHNNIE WALKER RED 70 CL.\n",
      "testName\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "item = next(Tester.query('0000009'))\n",
    "print(f'engname is {item.data.get(\"pr_engname\")}')\n",
    "\n",
    "updatedItem = Tester.updateWithDict(item,{'pr_engname':'testName'})\n",
    "assert updatedItem.data.get('pr_engname') == 'testName'\n",
    "print(updatedItem.data.get('pr_engname'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## update with list of dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass_json(undefined=Undefined.INCLUDE)\n",
    "@dataclass\n",
    "class Product:\n",
    "  iprcode: str\n",
    "  cprcode: str\n",
    "  data: CatchAll\n",
    "@dataclass_json\n",
    "@dataclass\n",
    "class ValueUpdate:\n",
    "  items: List[Product]\n",
    "#export\n",
    "@add_class_method(Updater)\n",
    "def valueUpdate2(cls, inputs):\n",
    "    ''' \n",
    "      check for difference and batch update the changes in product data\n",
    "    '''\n",
    "    t0 = datetime.now()\n",
    "    ### validate input\n",
    "    try:\n",
    "      validInputs = ValueUpdate.from_dict(inputs).to_dict().get('items')\n",
    "    except Exception as e:\n",
    "      raise KeyError(f'input failed validation {e}')\n",
    "      return\n",
    "    \n",
    "    itemsUpdated = {'success':0, 'failure': 0, 'skipped': 0 ,'failureMessage':[], 'timetaken(ms)': 0}\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    logging.info(f'there are {len(validInputs)} products to update')\n",
    "\n",
    "    print(f'input validated {(datetime.now()-t0).total_seconds()*1000} ms')\n",
    "    ##### dividing input into batch of 500\n",
    "    inputBatches = chunks(validInputs, 500)\n",
    "    print(f'divided into chunks {(datetime.now()-t0).total_seconds()*1000} ms')\n",
    "    items = cls.loadFromS3()\n",
    "    print(f'get all from s3 {(datetime.now()-t0).total_seconds()*1000} ms')\n",
    "    \n",
    "    for inputBatch in inputBatches:\n",
    "      with cls.batch_write() as batch:\n",
    "        # loop through each product\n",
    "        for input_ in inputBatch:\n",
    "          iprcode = input_['iprcode']\n",
    "          cprcode = input_['cprcode']\n",
    "\n",
    "          # check if product is in the database, if not, create an empty class with the product code\n",
    "#           incumbentBr = next(cls.query(iprcode , cls.cprcode == cprcode), cls(iprcode = iprcode, cprcode = cprcode, data = {}))\n",
    "          incumbentBr = cls.fromDict(items.get(iprcode) or {'iprcode': iprcode, 'cprcode': cprcode})\n",
    "          # save original data to a variable\n",
    "          originalData = incumbentBr.data.copy()\n",
    "          # update data\n",
    "          updatedData = cls.updateWithDict(incumbentBr, input_)\n",
    "\n",
    "          logging.info(f'incumbentBr is {incumbentBr.iprcode}\\n, prcode is {iprcode}')\n",
    "\n",
    "          # check for difference\n",
    "          try:\n",
    "            if updatedData.data != originalData:\n",
    "              logging.info(f'product {iprcode} has changed from \\n{originalData} \\n{updatedData.data}')\n",
    "              batch.save(updatedData)\n",
    "              itemsUpdated['success'] += 1\n",
    "            else:\n",
    "              logging.info(f'no change for {iprcode}')\n",
    "              itemsUpdated['skipped'] += 1\n",
    "          except Exception as e:\n",
    "            itemsUpdated['failure'] += 1\n",
    "            itemsUpdated['failureMessage'].append(e)\n",
    "          \n",
    "        # log time taken\n",
    "        itemsUpdated['timetaken(ms)'] = (datetime.now()- t0).total_seconds()*1000\n",
    "    return itemsUpdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cprcode                          0171670\n",
       "iprcode                          0171670\n",
       "oprcode                          0171670\n",
       "ordertype                              Y\n",
       "pr_abb              JIRAPAT YOUNG KALE 2\n",
       "pr_active                              Y\n",
       "pr_cgcode                             05\n",
       "pr_code                          0171670\n",
       "pr_dpcode                             19\n",
       "pr_engname      JIRAAT YOUNG KALE 200 G.\n",
       "pr_ggcode                            057\n",
       "pr_market        JIRAPAT ยอดคะน้า 200 G.\n",
       "pr_name          JIRAPAT ยอดคะน้า 200 G.\n",
       "pr_puqty                               1\n",
       "pr_sa_method                           1\n",
       "pr_sucode1                         CM845\n",
       "pr_suref3                              A\n",
       "prtype                                 I\n",
       "psqty                                  1\n",
       "pstype                                 1\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleProducts = [{ 'cprcode': '0171670', 'iprcode': '0171670', 'oprcode': '0171670', 'ordertype': 'Y', 'pr_abb': 'JIRAPAT YOUNG KALE 2', 'pr_active': 'Y', 'pr_cgcode': '05', 'pr_code': '0171670', 'pr_dpcode': '19', 'pr_engname': 'JIRAAT YOUNG KALE 200 G.', 'pr_ggcode': '057', 'pr_market': 'JIRAPAT ยอดคะน้า 200 G.', 'pr_name': 'JIRAPAT ยอดคะน้า 200 G.', 'pr_puqty': '1', 'pr_sa_method': '1', 'pr_sucode1': 'CM845', 'pr_suref3': 'A', 'prtype': 'I', 'psqty': '1', 'pstype': '1'}] #ProductDatabase.valueUpdate({'items':sampleProducts})\n",
    "product = sampleProducts[0]\n",
    "Tester.fromDict(product).toSeries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
