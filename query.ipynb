{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query\n",
    "Codes used to query database\n",
    "This includes\n",
    "## singleProductQuery\n",
    "## branchQuery\n",
    "## validateInputQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from nicHelper.wrappers import add_class_method, add_method, add_static_method\n",
    "from nicHelper.dictUtil import printDict\n",
    "from dataclasses_json import dataclass_json, Undefined, CatchAll\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from typing import List\n",
    "from s3bz.s3bz import S3\n",
    "import pickle, json , boto3, zlib, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing environment variable 'INVENTORY_BUCKET_NAME' in query NB\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "try:\n",
    "  INVENTORY_BUCKET_NAME = os.environ['INVENTORY_BUCKET_NAME']\n",
    "except Exception as e:\n",
    "  print(f'missing environment variable {e} in query NB')\n",
    "  INVENTORY_BUCKET_NAME = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Querier:\n",
    "  \n",
    "  @staticmethod\n",
    "  def validateInputQuery(keys: list, input:dict):\n",
    "    '''\n",
    "      check if input query contains the valid key\n",
    "      data should have the following structure\n",
    "      key is a list of keys to check\n",
    "\n",
    "      ib_prcode: String?\n",
    "      ib_brcode: String?\n",
    "\n",
    "      option, one of or both of the ib_procde must be present\n",
    "    '''\n",
    "    for key in keys:\n",
    "      if key not in input.keys():\n",
    "        raise ValueError(f\"key {key} is missing from the input\")\n",
    "      if not input.get(key).isdigit():\n",
    "        raise ValueError(f'key is not convertable to in {input.get(key)}')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "\n",
    "os.environ['DATABASE_TABLE_NAME'] = 'product-table-dev-manual'\n",
    "os.environ['REGION'] = 'ap-southeast-1'\n",
    "os.environ['INVENTORY_BUCKET_NAME'] = 'product-bucket-dev-manual'\n",
    "os.environ['INPUT_BUCKET_NAME'] = 'input-product-bucket-dev-manual'\n",
    "DAX_ENDPOINT = 'longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111'\n",
    "os.environ['LINEKEY'] = '2uAfV4AoYglUGmKTAk2xNOm0aV2Ufgh1BQPvQl9vJd4'\n",
    "REGION = 'ap-southeast-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dax endpoint missing 'DAX_ENDPOINT'\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from villaProductDatabase.database import ProductDatabase\n",
    "class Tester(Querier, ProductDatabase):\n",
    "  class Meta:\n",
    "    table_name = os.environ['DATABASE_TABLE_NAME']\n",
    "    region = os.environ['REGION']\n",
    "    billing_mode='PAY_PER_REQUEST'\n",
    "    dax_read_endpoints = [DAX_ENDPOINT] if DAX_ENDPOINT else None\n",
    "    dax_write_endpoints = [DAX_ENDPOINT] if DAX_ENDPOINT else None\n",
    "  pass\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All product Query (get signedUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_class_method(Querier)\n",
    "def allQuery(cls, key = 'allData', bucket = os.environ.get('INVENTORY_BUCKET_NAME'), **kwargs):\n",
    "  print(bucket)\n",
    "  result = S3.presign(key, bucket = bucket, **kwargs)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product-bucket-dev-manual\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://product-bucket-dev-manual.s3-accelerate.amazonaws.com/allData?AWSAccessKeyId=AKIAVX4Z5TKDSNNNULGB&Signature=ILqpDPg4J2Vy5VxiAA%2FT3nmNliw%3D&Expires=1608103361'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = Tester.allQuery()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.13 s, sys: 236 ms, total: 4.36 s\n",
      "Wall time: 4.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = S3.load(key='allData', bucket = os.environ['INVENTORY_BUCKET_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 101 ms, sys: 20.5 ms, total: 121 ms\n",
      "Wall time: 269 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = S3.loadFile(key='allData', path='/tmp/test', bucket = os.environ['INVENTORY_BUCKET_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@add_class_method(Querier)\n",
    "def loadFromS3(cls, bucketName= os.environ.get('INVENTORY_BUCKET_NAME'), key = 'allData', **kwargs):\n",
    "  '''\n",
    "  this is not a real time function, there may be a delay of sync between\n",
    "  the main dynamodb database and the cache\n",
    "  '''\n",
    "  logging.info(f'loading from {bucketName}')\n",
    "  logging.info(f'user is {kwargs.get(\"user\")}')\n",
    "  return S3.load(key=key, bucket = bucketName,  **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.02 s, sys: 197 ms, total: 4.22 s\n",
      "Wall time: 4.76 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0217153',\n",
       "  {'0217153': {'cprcode': '0217153',\n",
       "    'iprcode': '0217153',\n",
       "    'oprcode': '0217153',\n",
       "    'ordertype': 'Y',\n",
       "    'pr_abb': 'COCOA LOCO MILK CHOC',\n",
       "    'pr_active': 'Y',\n",
       "    'pr_cgcode': '98',\n",
       "    'pr_code': '0217153',\n",
       "    'pr_dpcode': '28',\n",
       "    'pr_engname': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.',\n",
       "    'pr_ggcode': '003',\n",
       "    'pr_market': 'COCOA LOCO MILK CHOCOLATE OWL',\n",
       "    'pr_name': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.',\n",
       "    'pr_puqty': '24.00',\n",
       "    'pr_sa_method': '1',\n",
       "    'pr_sucode1': 'F1239',\n",
       "    'pr_suref3': 'S',\n",
       "    'prtype': 'I',\n",
       "    'psqty': '1',\n",
       "    'pstype': '1',\n",
       "    'pr_country_th': '',\n",
       "    'pr_country_en': 'United Kingdom',\n",
       "    'pr_keyword_th': '',\n",
       "    'pr_keyword_en': '',\n",
       "    'pr_filter_th': '',\n",
       "    'pr_filter_en': '',\n",
       "    'online_category_l1_th': '',\n",
       "    'online_category_l1_en': '',\n",
       "    'online_category_l2_th': '',\n",
       "    'online_category_l2_en': '',\n",
       "    'online_category_l3_th': '',\n",
       "    'online_category_l3_en': '',\n",
       "    'villa_category_l1_en': 'Dry Grocery',\n",
       "    'villa_category_l2_en': 'Grocery',\n",
       "    'villa_category_l3_en': 'Cookies & Snacks',\n",
       "    'villa_category_l4_en': 'Biscuits & Crackers',\n",
       "    'content_en': '0217153 COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.',\n",
       "    'content_th': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.',\n",
       "    'hema_brand_th': '',\n",
       "    'hema_brand_en': '',\n",
       "    'hema_sizedesc': '',\n",
       "    'pr_brand_en': '',\n",
       "    'pr_brand_th': '',\n",
       "    'pr_online_name_en': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.',\n",
       "    'pr_online_name_th': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.',\n",
       "    'hema_name_en': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.',\n",
       "    'hema_name_th': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.',\n",
       "    'pr_name_en': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.',\n",
       "    'pr_name_th': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.',\n",
       "    'pr_barcode': '5060148383378',\n",
       "    'pr_barcode2': '506014838337',\n",
       "    'sort_weight': '0'}})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from itertools import islice\n",
    "data = ProductDatabase.loadFromS3()\n",
    "list(islice(data.items(),(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompress to s3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______ json dumping result ________\n",
      "CPU times: user 840 ms, sys: 68.3 ms, total: 909 ms\n",
      "Wall time: 905 ms\n",
      "______ json loading result ________\n",
      "CPU times: user 1.15 s, sys: 116 ms, total: 1.27 s\n",
      "Wall time: 1.26 s\n",
      "object size\n",
      "87.005143 MB\n",
      "----compressing zlib-json------\n",
      "CPU times: user 1.85 s, sys: 8.01 ms, total: 1.86 s\n",
      "Wall time: 1.86 s\n",
      "size of zlib data is\n",
      "9.646346 MB\n",
      "--decompressing zlib-json--\n",
      "CPU times: user 262 ms, sys: 56.2 ms, total: 318 ms\n",
      "Wall time: 317 ms\n",
      "------compressing bz json------\n",
      "CPU times: user 15.3 s, sys: 10.5 ms, total: 15.3 s\n",
      "Wall time: 15.3 s\n",
      "size of bz2 data is\n",
      "6.167249 MB\n",
      "------decompressing bz json------\n",
      "CPU times: user 2.7 s, sys: 52 ms, total: 2.75 s\n",
      "Wall time: 2.75 s\n",
      "______ pickle dumping result ________\n",
      "CPU times: user 623 ms, sys: 60.1 ms, total: 683 ms\n",
      "Wall time: 681 ms\n",
      "______ pickle loading result ________\n",
      "CPU times: user 391 ms, sys: 39.7 ms, total: 431 ms\n",
      "Wall time: 429 ms\n",
      "object size\n",
      "40.872868 MB\n",
      "-----compressing zlib pickle-----\n",
      "CPU times: user 1.33 s, sys: 0 ns, total: 1.33 s\n",
      "Wall time: 1.33 s\n",
      "size of zlib pickle is\n",
      "8.304423 MB\n",
      "-----decompressing zlib pickle-----\n",
      "CPU times: user 197 ms, sys: 36 ms, total: 233 ms\n",
      "Wall time: 233 ms\n",
      "------compressing bz pickle-------\n",
      "CPU times: user 4.83 s, sys: 0 ns, total: 4.83 s\n",
      "Wall time: 4.84 s\n",
      "size of bz2 pickle is\n",
      "5.976561 MB\n",
      "-----decompressing bz pickle-----\n",
      "CPU times: user 1.56 s, sys: 11.8 ms, total: 1.57 s\n",
      "Wall time: 1.57 s\n"
     ]
    }
   ],
   "source": [
    "import sys, zlib, bz2\n",
    "print('______ json dumping result ________')\n",
    "%time bytesData = json.dumps(data).encode()\n",
    "print('______ json loading result ________')\n",
    "%time _ = json.loads(bytesData.decode())\n",
    "print('object size')\n",
    "print(sys.getsizeof(bytesData)/1e6,'MB')\n",
    "print('----compressing zlib-json------')\n",
    "%time zlibData = zlib.compress(bytesData)\n",
    "print('size of zlib data is')\n",
    "print(sys.getsizeof(zlibData)/1e6,'MB')\n",
    "print('--decompressing zlib-json--')\n",
    "%time _ = zlib.decompress(zlibData)\n",
    "print('------compressing bz json------')\n",
    "%time bzData = bz2.compress(bytesData)\n",
    "print('size of bz2 data is')\n",
    "print(sys.getsizeof(bzData)/1e6,'MB')\n",
    "print('------decompressing bz json------')\n",
    "%time _ = bz2.decompress(bzData)\n",
    "\n",
    "print('______ pickle dumping result ________')\n",
    "%time pickleData = pickle.dumps(data)\n",
    "print('______ pickle loading result ________')\n",
    "%time _ = pickle.loads(pickleData)\n",
    "print('object size')\n",
    "print(sys.getsizeof(pickleData)/1e6,'MB')\n",
    "print('-----compressing zlib pickle-----')\n",
    "%time zlibPickle = zlib.compress(pickleData)\n",
    "print('size of zlib pickle is')\n",
    "print(sys.getsizeof(zlibPickle)/1e6,'MB')\n",
    "print('-----decompressing zlib pickle-----')\n",
    "%time _ = zlib.decompress(zlibPickle)\n",
    "print('------compressing bz pickle-------')\n",
    "%time bzPickle = bz2.compress(pickleData)\n",
    "print('size of bz2 pickle is')\n",
    "print(sys.getsizeof(bzPickle)/1e6,'MB')\n",
    "print('-----decompressing bz pickle-----')\n",
    "%time _ = bz2.decompress(bzPickle)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./zlibPickle.gz', 'wb') as f:\n",
    "  f.write(zlibPickle)\n",
    "with open('./zlibjson.gz', 'wb') as f:\n",
    "  f.write(zlibData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.17 s, sys: 88.4 ms, total: 1.26 s\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = json.loads(bytesData.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'dict'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## test gz2 compression\n",
    "zlib.compress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-b7122bbe7b80>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-b7122bbe7b80>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    S3.\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def lambdaDecompressS3(event, *args):\n",
    "  S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list product query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass_json\n",
    "@dataclass\n",
    "class ProductsFromList:\n",
    "  iprcodes: List[str]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@add_class_method(Querier)\n",
    "def productsFromList(cls,iprcodes:List[str])->dict:\n",
    "  database = cls.loadFromS3()\n",
    "  return [database[iprcode] for iprcode in iprcodes if iprcode in database.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0217153\n",
      " cprcode : 0217153\n",
      " iprcode : 0217153\n",
      " oprcode : 0217153\n",
      " ordertype : Y\n",
      " pr_abb : COCOA LOCO\n",
      " pr_active : Y\n",
      " pr_cgcode : 98\n",
      " pr_code : 0217153\n",
      " pr_dpcode : 28\n",
      " pr_engname : COCOA LOCO\n",
      " pr_ggcode : 003\n",
      " pr_market : COCOA LOCO\n",
      " pr_name : COCOA LOCO\n",
      " pr_puqty : 24.00\n",
      " pr_sa_method : 1\n",
      " pr_sucode1 : F1239\n",
      " pr_suref3 : S\n",
      " prtype : I\n",
      " psqty : 1\n",
      " pstype : 1\n",
      " pr_country_th : \n",
      " pr_country_en : United Kin\n",
      " pr_keyword_th : \n",
      " pr_keyword_en : \n",
      " pr_filter_th : \n",
      " pr_filter_en : \n",
      " online_category_l1_th : \n",
      " online_category_l1_en : \n",
      " online_category_l2_th : \n",
      " online_category_l2_en : \n",
      " online_category_l3_th : \n",
      " online_category_l3_en : \n",
      " villa_category_l1_en : Dry Grocer\n",
      " villa_category_l2_en : Grocery\n",
      " villa_category_l3_en : Cookies & \n",
      " villa_category_l4_en : Biscuits &\n",
      " content_en : 0217153 CO\n",
      " content_th : COCOA LOCO\n",
      " hema_brand_th : \n",
      " hema_brand_en : \n",
      " hema_sizedesc : \n",
      " pr_brand_en : \n",
      " pr_brand_th : \n",
      " pr_online_name_en : COCOA LOCO\n",
      " pr_online_name_th : COCOA LOCO\n",
      " hema_name_en : COCOA LOCO\n",
      " hema_name_th : COCOA LOCO\n",
      " pr_name_en : COCOA LOCO\n",
      " pr_name_th : COCOA LOCO\n",
      " pr_barcode : 5060148383\n",
      " pr_barcode2 : 5060148383\n",
      " sort_weight : 0\n",
      "CPU times: user 3.86 s, sys: 269 ms, total: 4.13 s\n",
      "Wall time: 4.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = Tester.productsFromList(['0217153','203915','0000009'])\n",
    "print(len(result))\n",
    "printDict(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SingleProductQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_class_method(Querier)\n",
    "def singleProductQuery(cls, input):\n",
    "  if not cls.validateInputQuery(['iprcode'] , input): return f\"error input {input}\"\n",
    "  if (result:=next(cls.query(input.get('iprcode')),None)): return result\n",
    "  else: raise Exception('product not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "product not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-dc891eb79c19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingleProductQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'iprcode'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'1234'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SageMaker/.persisted_conda/python38/lib/python3.8/site-packages/nicHelper/wrappers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Note we are not binding func, but wrapper which accepts self but does exactly the same as func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-6b6de491805e>\u001b[0m in \u001b[0;36msingleProductQuery\u001b[0;34m(cls, input)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidateInputQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iprcode'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"error input {input}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m:=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iprcode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'product not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: product not found"
     ]
    }
   ],
   "source": [
    "Tester.singleProductQuery({'iprcode':'1234'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Tester.singleProductQuery({'iprcode':'0000009'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
