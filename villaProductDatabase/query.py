# AUTOGENERATED! DO NOT EDIT! File to edit: query.ipynb (unless otherwise specified).

__all__ = ['Querier', 'loadFromS3', 'ProductsFromList', 'productsFromList']

# Cell
import pandas as pd
from datetime import datetime
from nicHelper.wrappers import add_class_method, add_method, add_static_method
from nicHelper.dictUtil import printDict
from dataclasses_json import dataclass_json, Undefined, CatchAll
from dataclasses import dataclass
import logging
from typing import List
from s3bz.s3bz import S3
import pickle, json , boto3, zlib, os

# Cell
try:
  INVENTORY_BUCKET_NAME = os.environ['INVENTORY_BUCKET_NAME']
except Exception as e:
  print(f'missing environment variable {e} in query NB')
  INVENTORY_BUCKET_NAME = None

# Cell
class Querier:

  @staticmethod
  def validateInputQuery(keys: list, input:dict):
    '''
      check if input query contains the valid key
      data should have the following structure
      key is a list of keys to check

      ib_prcode: String?
      ib_brcode: String?

      option, one of or both of the ib_procde must be present
    '''
    for key in keys:
      if key not in input.keys():
        raise ValueError(f"key {key} is missing from the input")
      if not input.get(key).isdigit():
        raise ValueError(f'key is not convertable to in {input.get(key)}')
    return True

# Cell
@add_class_method(Querier)
def loadFromS3(cls, bucketName= os.environ.get('INVENTORY_BUCKET_NAME'), key = 'allData', **kwargs):
  '''
  this is not a real time function, there may be a delay of sync between
  the main dynamodb database and the cache
  '''
  logging.info(f'loading from {bucketName}')
  logging.info(f'user is {kwargs.get("user")}')
  return S3.load(key=key, bucket = bucketName,  **kwargs)

# Cell
@dataclass_json
@dataclass
class ProductsFromList:
  iprcodes: List[str]


# Cell
@add_class_method(Querier)
def productsFromList(cls,iprcodes:List[str])->dict:
  database = cls.loadFromS3()
  return [database[iprcode] for iprcode in iprcodes if iprcode in database.keys()]