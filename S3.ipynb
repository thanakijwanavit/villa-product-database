{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3Cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deals with everything that reads and write to the s3 cache for the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pickle, os\n",
    "\n",
    "os.environ['DATABASE_TABLE_NAME'] = 'product-table-dev-manual'\n",
    "os.environ['REGION'] = 'ap-southeast-1'\n",
    "os.environ['INVENTORY_BUCKET_NAME'] = 'product-bucket-dev-manual'\n",
    "os.environ['INPUT_BUCKET_NAME'] = 'input-product-bucket-dev-manual'\n",
    "os.environ['DAX_ENDPOINT'] = 'longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111'\n",
    "os.environ['LINEKEY'] = '2uAfV4AoYglUGmKTAk2xNOm0aV2Ufgh1BQPvQl9vJd4'\n",
    "REGION = 'ap-southeast-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from s3bz.s3bz import S3\n",
    "from nicHelper.wrappers import add_method, add_class_method, add_static_method\n",
    "from nicHelper.dictUtil import stripDict, printDict, hashDict, saveStringToFile, loadStringFromFile, saveDictToFile, loadDictFromFile\n",
    "from nicHelper.exception import errorString\n",
    "import nicHelper.pdUtils as pdUtils\n",
    "from dict_hash import dict_hash, sha256\n",
    "from base64 import b64encode, b64decode\n",
    "from pandas.util import hash_pandas_object\n",
    "from hashlib import sha1\n",
    "import pandas as pd\n",
    "import os, logging, zlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111\n",
      "longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111\n",
      "longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111\n",
      "longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111\n"
     ]
    }
   ],
   "source": [
    "from villaProductDatabase.database import ProductDatabase\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import os\n",
    "DBHASHLOCATION = '/mnt/efs/database.hash'\n",
    "DBCACHELOCATION = '/mnt/efs/database.cache'\n",
    "DATABASE_TABLE_NAME = os.environ.get('DATABASE_TABLE_NAME')\n",
    "INVENTORY_BUCKET_NAME = os.environ.get('INVENTORY_BUCKET_NAME')\n",
    "INPUT_BUCKET_NAME = os.environ.get('INPUT_BUCKET_NAME')\n",
    "REGION = os.environ.get('REGION') or 'ap-southeast-1'\n",
    "ACCESS_KEY_ID = os.environ.get('USER') or None\n",
    "SECRET_ACCESS_KEY = os.environ.get('PW') or None\n",
    "LINEKEY= os.environ.get('LINEKEY')\n",
    "ALLDATAKEY = 'allData'\n",
    "DEFAULTKEYS = ['cprcode', 'iprcode', 'oprcode', 'ordertype', 'pr_abb', 'pr_active', 'pr_cgcode', 'pr_code', 'pr_dpcode', 'pr_engname', 'pr_ggcode', 'pr_market', 'pr_name', 'pr_puqty', 'pr_sa_method', 'pr_sucode1', 'pr_suref3', 'prtype', 'psqty', 'pstype']\n",
    "  \n",
    "try:\n",
    "  DAX_ENDPOINT = os.environ['DAX_ENDPOINT']\n",
    "  print(DAX_ENDPOINT)\n",
    "except KeyError as e:\n",
    "  print(f'dax endpoint missing {e}')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class S3Cache:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester( S3Cache, ProductDatabase):\n",
    "  class Meta:\n",
    "    table_name = os.environ['DATABASE_TABLE_NAME']\n",
    "    region = os.environ['REGION']\n",
    "    billing_mode='PAY_PER_REQUEST'\n",
    "    dax_read_endpoints = [DAX_ENDPOINT] if DAX_ENDPOINT else None\n",
    "    dax_write_endpoints = [DAX_ENDPOINT] if DAX_ENDPOINT else None\n",
    "  pass\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save and load local hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@add_class_method(S3Cache)\n",
    "def loadFromCache(cls, key=ALLDATAKEY, localCache=DBCACHELOCATION, \n",
    "                  localHash=DBHASHLOCATION, bucket=INVENTORY_BUCKET_NAME):\n",
    "  ## check for local object and its hash\n",
    "  if os.path.exists(localCache) and os.path.exists(localHash):\n",
    "    try:\n",
    "      localHash = pdUtils.loadLocalHash(path=localHash)\n",
    "      logging.debug(f'localHash is {localHash}')\n",
    "      remoteHash = pdUtils.loadRemoteHash(key=key, bucket=bucket)\n",
    "      logging.debug(f'remoteHash is {remoteHash}')\n",
    "\n",
    "      if localHash == remoteHash:\n",
    "        print('data is still in sync, using local cache')\n",
    "        db = pdUtils.loadLocalCache(path=localCache)\n",
    "        return db\n",
    "      else: \n",
    "        print('remote hash is not the same, load remote cache')\n",
    "    except Exception as e: print(f'local loading error{e}, loading remote hash')\n",
    "  ### load from remote cache\n",
    "  try:\n",
    "    db = pdUtils.loadRemoteCache(key=key, bucket=bucket)\n",
    "    pdUtils.saveLocalCache(db, path=localCache)\n",
    "    pdUtils.saveLocalHash(db, path = localHash)\n",
    "  except Exception as e:\n",
    "    print(f'locding remtoe failed {e} returning blank df')\n",
    "    db = pd.DataFrame(columns = DEFAULTKEYS)\n",
    "  ### save to local cache\n",
    "  return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDict = {'cprcode': '0171670', 'iprcode': '0171670', 'oprcode': '0171670', 'ordertype': 'Y', 'pr_abb': 'JIRAPAT YOUG KALE 2', 'pr_active': 'Y', 'pr_cgcode': '05', 'pr_code': '0171670', 'pr_dpcode': '19', 'pr_engname': 'JIRAPAT YOUNG KALE 200 G.', 'pr_ggcode': '057', 'pr_market': 'JIRAPAT ยอดคะน้า 200 G.', 'pr_name': 'JIRAPAT ยอดคะน้า 200 G.', 'pr_puqty': '1', 'pr_sa_method': '1', 'pr_sucode1': 'CM845     ', 'pr_suref3': 'A', 'prtype': 'I', 'psqty': '1', 'pstype': '1'}\n",
    "sampleDict.keys()\n",
    "keys = ['cprcode', 'iprcode', 'oprcode', 'ordertype', 'pr_abb', 'pr_active', 'pr_cgcode', 'pr_code', 'pr_dpcode', 'pr_engname', 'pr_ggcode', 'pr_market', 'pr_name', 'pr_puqty', 'pr_sa_method', 'pr_sucode1', 'pr_suref3', 'prtype', 'psqty', 'pstype']\n",
    "pd.DataFrame(columns = keys)\n",
    "DUMMYDATA = {'cprcode': '000000', 'iprcode': '000000', 'oprcode': '0171670', 'ordertype': 'Y', 'pr_abb': 'JIRAPAT YOUG KALE 2', 'pr_active': 'Y', 'pr_cgcode': '05', 'pr_code': '0171670', 'pr_dpcode': '19', 'pr_engname': 'JIRAPAT YOUNG KALE 200 G.', 'pr_ggcode': '057', 'pr_market': 'JIRAPAT ยอดคะน้า 200 G.', 'pr_name': 'JIRAPAT ยอดคะน้า 200 G.', 'pr_puqty': '1', 'pr_sa_method': '1', 'pr_sucode1': 'CM845     ', 'pr_suref3': 'A', 'prtype': 'I', 'psqty': '1', 'pstype': '1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using accelerate endpoint\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading hashkey allData-hash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using accelerate endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded hash is d0c0857f93ea21a99bc59a7c459dea6b8341d7cf\n",
      "data is still in sync, using local cache\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "db = Tester.loadFromCache()\n",
    "assert db.shape > (10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using accelerate endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locding remtoe failed An error occurred (404) when calling the HeadObject operation: Not Found returning blank df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cprcode</th>\n",
       "      <th>iprcode</th>\n",
       "      <th>oprcode</th>\n",
       "      <th>ordertype</th>\n",
       "      <th>pr_abb</th>\n",
       "      <th>pr_active</th>\n",
       "      <th>pr_cgcode</th>\n",
       "      <th>pr_code</th>\n",
       "      <th>pr_dpcode</th>\n",
       "      <th>pr_engname</th>\n",
       "      <th>pr_ggcode</th>\n",
       "      <th>pr_market</th>\n",
       "      <th>pr_name</th>\n",
       "      <th>pr_puqty</th>\n",
       "      <th>pr_sa_method</th>\n",
       "      <th>pr_sucode1</th>\n",
       "      <th>pr_suref3</th>\n",
       "      <th>prtype</th>\n",
       "      <th>psqty</th>\n",
       "      <th>pstype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [cprcode, iprcode, oprcode, ordertype, pr_abb, pr_active, pr_cgcode, pr_code, pr_dpcode, pr_engname, pr_ggcode, pr_market, pr_name, pr_puqty, pr_sa_method, pr_sucode1, pr_suref3, prtype, psqty, pstype]\n",
       "Index: []"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tester.loadFromCache(key='doestExist', localCache='doesntExist', localHash='doesntExist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load remote hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@add_class_method(S3Cache)\n",
    "def saveRemoteCache(cls ,db:pd.DataFrame, key= ALLDATAKEY,\n",
    "                   bucket = INVENTORY_BUCKET_NAME, localCachePath=DBCACHELOCATION,\n",
    "                   localHashPath=DBHASHLOCATION):\n",
    "  if db.empty:\n",
    "    db = pd.DataFrame([DUMMYDATA])\n",
    "  db.columns = db.columns.astype(str)\n",
    "  db = db.reset_index(drop=True)\n",
    "  \n",
    "  print(db)\n",
    "  pdUtils.saveRemoteCache(data=db, key= key, \n",
    "                          bucket=bucket, localCachePath=localCachePath, \n",
    "                          localHashPath=localHashPath)\n",
    "  jsonDb = db.to_json(orient='split')\n",
    "  zlibArc = zlib.compress(jsonDb.encode())\n",
    "  tmpPath = '/tmp/zlibJsonCache.zl'\n",
    "  with open(tmpPath, 'wb') as f:\n",
    "    f.write(zlibArc)\n",
    "  S3.saveFile(key=f'{key}-json.zl',path=tmpPath,bucket=bucket)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using accelerate endpoint\n",
      "INFO:root:data was saved to s3\n",
      "INFO:root:using accelerate endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cprcode  iprcode  oprcode ordertype               pr_abb pr_active  \\\n",
      "0  0171670  0171670  0171670         Y  JIRAPAT YOUG KALE 2         Y   \n",
      "\n",
      "  pr_cgcode  pr_code pr_dpcode                 pr_engname pr_ggcode  \\\n",
      "0        05  0171670        19  JIRAPAT YOUNG KALE 200 G.       057   \n",
      "\n",
      "                 pr_market                  pr_name pr_puqty pr_sa_method  \\\n",
      "0  JIRAPAT ยอดคะน้า 200 G.  JIRAPAT ยอดคะน้า 200 G.        1            1   \n",
      "\n",
      "   pr_sucode1 pr_suref3 prtype psqty pstype  \n",
      "0  CM845              A      I     1      1  \n",
      "hashKey is allData-hash\n",
      "saving hash to s3\n",
      "saved hash d0c0857f93ea21a99bc59a7c459dea6b8341d7cf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using accelerate endpoint\n",
      "INFO:root:using accelerate endpoint\n",
      "INFO:root:using accelerate endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading hashkey allData-hash\n",
      "loaded hash is d0c0857f93ea21a99bc59a7c459dea6b8341d7cf\n",
      "data is still in sync, using local cache\n",
      "CPU times: user 123 ms, sys: 11.7 ms, total: 134 ms\n",
      "Wall time: 529 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "db = pd.DataFrame([sampleDict])\n",
    "Tester.saveRemoteCache(db)\n",
    "assert pdUtils.getDfHash(db.reset_index(drop=True)) == pdUtils.getDfHash(Tester.loadFromCache()), 'save fail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using accelerate endpoint\n",
      "INFO:root:using accelerate endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading hashkey allData-hash\n",
      "loaded hash is d0c0857f93ea21a99bc59a7c459dea6b8341d7cf\n",
      "data is still in sync, using local cache\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cprcode</th>\n",
       "      <th>iprcode</th>\n",
       "      <th>oprcode</th>\n",
       "      <th>ordertype</th>\n",
       "      <th>pr_abb</th>\n",
       "      <th>pr_active</th>\n",
       "      <th>pr_cgcode</th>\n",
       "      <th>pr_code</th>\n",
       "      <th>pr_dpcode</th>\n",
       "      <th>pr_engname</th>\n",
       "      <th>pr_ggcode</th>\n",
       "      <th>pr_market</th>\n",
       "      <th>pr_name</th>\n",
       "      <th>pr_puqty</th>\n",
       "      <th>pr_sa_method</th>\n",
       "      <th>pr_sucode1</th>\n",
       "      <th>pr_suref3</th>\n",
       "      <th>prtype</th>\n",
       "      <th>psqty</th>\n",
       "      <th>pstype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0171670</td>\n",
       "      <td>0171670</td>\n",
       "      <td>0171670</td>\n",
       "      <td>Y</td>\n",
       "      <td>JIRAPAT YOUG KALE 2</td>\n",
       "      <td>Y</td>\n",
       "      <td>05</td>\n",
       "      <td>0171670</td>\n",
       "      <td>19</td>\n",
       "      <td>JIRAPAT YOUNG KALE 200 G.</td>\n",
       "      <td>057</td>\n",
       "      <td>JIRAPAT ยอดคะน้า 200 G.</td>\n",
       "      <td>JIRAPAT ยอดคะน้า 200 G.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>CM845</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cprcode  iprcode  oprcode ordertype               pr_abb pr_active  \\\n",
       "0  0171670  0171670  0171670         Y  JIRAPAT YOUG KALE 2         Y   \n",
       "\n",
       "  pr_cgcode  pr_code pr_dpcode                 pr_engname pr_ggcode  \\\n",
       "0        05  0171670        19  JIRAPAT YOUNG KALE 200 G.       057   \n",
       "\n",
       "                 pr_market                  pr_name pr_puqty pr_sa_method  \\\n",
       "0  JIRAPAT ยอดคะน้า 200 G.  JIRAPAT ยอดคะน้า 200 G.        1            1   \n",
       "\n",
       "   pr_sucode1 pr_suref3 prtype psqty pstype  \n",
       "0  CM845              A      I     1      1  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tester.loadFromCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.reset_index(drop=True).to_feather('/tmp/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset S3 Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@add_class_method(S3Cache)\n",
    "def resetS3Cache(cls, bucketName= INVENTORY_BUCKET_NAME, key = 'allData', limit=10000, **kwargs):\n",
    "  ''' upload changes to s3'''\n",
    "  ###### get all data\n",
    "  items:List[cls] = cls.scanDb(limit=limit)\n",
    "  db:pd.DataFrame = cls.toDf(items)\n",
    "  print(f'{db.shape} changes to update')\n",
    "  cls.saveRemoteCache(db)\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20) changes to update\n",
      "   cprcode  iprcode  oprcode ordertype                pr_abb pr_active  \\\n",
      "0  0171670  0171670  0171670         Y  JIRAPAT YOUNG KALE 2         Y   \n",
      "\n",
      "  pr_cgcode  pr_code pr_dpcode                pr_engname pr_ggcode  \\\n",
      "0        05  0171670        19  JIRAAT YOUNG KALE 200 G.       057   \n",
      "\n",
      "                 pr_market                  pr_name pr_puqty pr_sa_method  \\\n",
      "0  JIRAPAT ยอดคะน้า 200 G.  JIRAPAT ยอดคะน้า 200 G.        1            1   \n",
      "\n",
      "  pr_sucode1 pr_suref3 prtype psqty pstype  \n",
      "0      CM845         A      I     1      1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using accelerate endpoint\n",
      "INFO:root:data was saved to s3\n",
      "INFO:root:using accelerate endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hashKey is allData-hash\n",
      "saving hash to s3\n",
      "saved hash 43a007725a68e2be2ca47be21c49845cf840b3ef\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:using accelerate endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 139 ms, sys: 3.67 ms, total: 142 ms\n",
      "Wall time: 523 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "Tester.resetS3Cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonDb = db.to_json(orient='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 100 µs, sys: 18 µs, total: 118 µs\n",
      "Wall time: 124 µs\n",
      "CPU times: user 49 µs, sys: 9 µs, total: 58 µs\n",
      "Wall time: 62.7 µs\n",
      "CPU times: user 376 µs, sys: 70 µs, total: 446 µs\n",
      "Wall time: 312 µs\n",
      "CPU times: user 26 µs, sys: 4 µs, total: 30 µs\n",
      "Wall time: 35.5 µs\n"
     ]
    }
   ],
   "source": [
    "import zlib, json\n",
    "%time jsonDb = db.to_json(orient='split')\n",
    "%time zlibArc = zlib.compress(jsonDb.encode())\n",
    "%time zlibObject = zlib.decompress(zlibArc).decode()\n",
    "%time dbDict = json.loads(zlibObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589\n",
      "279\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(jsonDb))\n",
    "print(sys.getsizeof(zlibArc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
