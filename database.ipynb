{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Class\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import logging\n",
    "logging.basicConfig(level= logging.WARNING)\n",
    "log = logging.getLogger(\"pynamodb\")\n",
    "log.setLevel(logging.DEBUG)\n",
    "log.setLevel(logging.WARNING)\n",
    "log.propagate = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pickle, os\n",
    "\n",
    "os.environ['DATABASE_TABLE_NAME'] = 'product-table-dev-manual'\n",
    "os.environ['REGION'] = 'ap-southeast-1'\n",
    "os.environ['INVENTORY_BUCKET_NAME'] = 'product-bucket-dev-manual'\n",
    "os.environ['INPUT_BUCKET_NAME'] = 'input-product-bucket-dev-manual'\n",
    "os.environ['DAX_ENDPOINT'] = 'longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111'\n",
    "os.environ['LINEKEY'] = '2uAfV4AoYglUGmKTAk2xNOm0aV2Ufgh1BQPvQl9vJd4'\n",
    "REGION = 'ap-southeast-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111\n",
      "longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pynamodb.models import Model\n",
    "from pynamodb.attributes import UnicodeAttribute, NumberAttribute, JSONAttribute, BooleanAttribute, BinaryAttribute\n",
    "from pynamodb.indexes import GlobalSecondaryIndex, AllProjection\n",
    "from botocore.config import Config\n",
    "from s3bz.s3bz import S3\n",
    "from pprint import pprint\n",
    "from nicHelper.wrappers import add_method, add_class_method, add_static_method\n",
    "from nicHelper.dictUtil import stripDict, printDict\n",
    "from nicHelper.exception import errorString\n",
    "from awsSchema.apigateway import Response, Event\n",
    "from dataclasses_json import dataclass_json, Undefined, CatchAll\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from villaProductDatabase.query import Querier\n",
    "from villaProductDatabase.helpers import Helpers\n",
    "from villaProductDatabase.s3 import S3Cache\n",
    "from villaProductDatabase.schema import KeySchema, createIndex\n",
    "from requests import post\n",
    "\n",
    "import pickle, json, boto3, bz2, requests, validators, os, logging, traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longtermcluster.vuu7lr.clustercfg.dax.apse1.cache.amazonaws.com:8111\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import os\n",
    "\n",
    "DATABASE_TABLE_NAME = os.environ.get('DATABASE_TABLE_NAME')\n",
    "INVENTORY_BUCKET_NAME = os.environ.get('INVENTORY_BUCKET_NAME')\n",
    "INPUT_BUCKET_NAME = os.environ.get('INPUT_BUCKET_NAME')\n",
    "REGION = os.environ.get('REGION') or 'ap-southeast-1'\n",
    "ACCESS_KEY_ID = os.environ.get('USER') or None\n",
    "SECRET_ACCESS_KEY = os.environ.get('PW') or None\n",
    "LINEKEY= os.environ.get('LINEKEY')\n",
    "  \n",
    "try:\n",
    "  DAX_ENDPOINT = os.environ['DAX_ENDPOINT']\n",
    "except KeyError as e:\n",
    "  DAX_ENDPOINT = None\n",
    "  print(f'dax endpoint missing {e}')\n",
    "  \n",
    "print(DAX_ENDPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Database Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# dont forget to import dependent classes from the relevant notebooks\n",
    "class ProductDatabase( Querier, Helpers, KeySchema, S3Cache):\n",
    "  class Meta:\n",
    "    aws_access_key_id = ACCESS_KEY_ID\n",
    "    aws_secret_access_key = SECRET_ACCESS_KEY\n",
    "    table_name = DATABASE_TABLE_NAME\n",
    "    region = REGION\n",
    "    billing_mode='PAY_PER_REQUEST'\n",
    "    dax_read_endpoints = [DAX_ENDPOINT] if DAX_ENDPOINT else None\n",
    "    dax_write_endpoints = [DAX_ENDPOINT] if DAX_ENDPOINT else None\n",
    "\n",
    "\n",
    "  TRUE = 'Y'\n",
    "  FALSE = 'N'\n",
    "  \n",
    "  # indexes\n",
    "  needsUpdateIndex = createIndex('needsUpdate','sellingPrice')\n",
    "  cprcodeIndex = createIndex('cprcode', 'sellingPrice')\n",
    "  oprcodeIndex = createIndex('oprcode', 'sellingPrice')\n",
    "  pr_dpcodeIndex = createIndex('pr_dpcode', 'sellingPrice')\n",
    "  pr_barcodeIndex = createIndex('pr_barcode', 'sellingPrice')\n",
    "  pr_barcode2Index = createIndex('pr_barcode2', 'sellingPrice')\n",
    "  pr_suref3Index = createIndex('pr_suref3', 'sellingPrice')\n",
    "  pr_sa_methodIndex = createIndex('pr_sa_method', 'sellingPrice')\n",
    "  \n",
    "  \n",
    "    \n",
    "  def __repr__(self):\n",
    "    return self.returnKW(self.data)\n",
    "  \n",
    "    \n",
    "  @staticmethod\n",
    "  def returnKW(inputDict):\n",
    "    outputStr = 'ProductDatabase Object\\n'\n",
    "    for k,v in inputDict.items():\n",
    "      outputStr += f'{k} {v}\\n'\n",
    "    return outputStr  \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set update status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@add_method(ProductDatabase)\n",
    "def setNoUpdate(self, batch = None):\n",
    "  self.needsUpdate = self.FALSE\n",
    "  if batch:\n",
    "    return batch.save(self)\n",
    "  else:\n",
    "    return self.save()\n",
    "  \n",
    "@add_method(ProductDatabase)\n",
    "def setUpdate(self, batch=None):\n",
    "  self.needsUpdate = self.TRUE\n",
    "  if batch:\n",
    "    return batch.save(self)\n",
    "  else:\n",
    "    return self.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n",
      "N\n",
      "CPU times: user 61 ms, sys: 24.2 ms, total: 85.2 ms\n",
      "Wall time: 180 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sku = '0000009'\n",
    "item = next(ProductDatabase.query(sku))\n",
    "item.setUpdate()\n",
    "item = next(ProductDatabase.query(sku))\n",
    "print(item.needsUpdate)\n",
    "item.setNoUpdate()\n",
    "item = next(ProductDatabase.query(sku))\n",
    "print(item.needsUpdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 202 ms, sys: 624 µs, total: 202 ms\n",
      "Wall time: 668 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with ProductDatabase.batch_write() as batch:\n",
    "  for product in ProductDatabase.scan(limit=500):\n",
    "    product.setUpdate(batch=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "##tests\n",
    "assert ProductDatabase.Meta.table_name == 'product-table-dev-manual', 'product table name not set'\n",
    "assert len(list(ProductDatabase.scan(limit=1))) == 1, 'db scan not working'\n",
    "assert len(list(ProductDatabase.needsUpdateIndex.query(ProductDatabase.TRUE))) > 1, 'cant find any needsUpdate item'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "### set test env\n",
    "sampleProducts = [{'cprcode': '0171670', 'iprcode': '0171670', 'oprcode': '0171670', 'ordertype': 'Y', 'pr_abb': 'JIRAPAT YOUNG KALE 2', 'pr_active': 'Y', 'pr_cgcode': '05', 'pr_code': '0171670', 'pr_dpcode': '19', 'pr_engname': 'JIRAPAT YOUNG KALE 200 G.', 'pr_ggcode': '057', 'pr_market': 'JIRAPAT ยอดคะน้า 200 G.', 'pr_name': 'JIRAPAT ยอดคะน้า 200 G.', 'pr_puqty': '1', 'pr_sa_method': '1', 'pr_sucode1': 'CM845     ', 'pr_suref3': 'A', 'prtype': 'I', 'psqty': '1', 'pstype': '1'}, {'cprcode': '0235141', 'iprcode': '0235141', 'oprcode': '0235141', 'ordertype': 'Y', 'pr_abb': 'EEBOO-PZCT3-PUZZLE', 'pr_active': 'Y', 'pr_cgcode': '08', 'pr_code': '0235141', 'pr_dpcode': '19', 'pr_engname': 'EEBOO,ANIMAL COUNTING PUZZLE_3ED,PZCT3', 'pr_ggcode': '113', 'pr_market': 'eeboo,PUZZLE-PZCT3', 'pr_name': 'EEBOO-PZCT3-ตัวต่อนับเลข ANIMAL COUNTING_3ED', 'pr_puqty': '1', 'pr_sa_method': '1', 'pr_sucode1': 'CM1979    ', 'pr_suref3': 'A', 'prtype': 'I', 'psqty': '1', 'pstype': '1'}, {'cprcode': '0217153', 'iprcode': '0217153', 'oprcode': '0217153', 'ordertype': 'Y', 'pr_abb': 'COCOA LOCO MILK CHOC', 'pr_active': 'Y', 'pr_cgcode': '98', 'pr_code': '0217153', 'pr_dpcode': '28', 'pr_engname': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_ggcode': '003', 'pr_market': 'COCOA LOCO MILK CHOCOLATE OWL', 'pr_name': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_puqty': '24', 'pr_sa_method': '1', 'pr_sucode1': 'F1222     ', 'pr_suref3': 'S', 'prtype': 'I', 'psqty': '1', 'pstype': '1'}, {'cprcode': '0182223', 'iprcode': '0182223', 'oprcode': '0182223', 'ordertype': 'Y', 'pr_abb': 'CIRIO PIZZASSIMO 400', 'pr_active': 'Y', 'pr_cgcode': '06', 'pr_code': '0182223', 'pr_dpcode': '06', 'pr_engname': 'CIRIO PIZZASSIMO 400G.', 'pr_ggcode': '004', 'pr_market': 'CIRIO ซอสทำพิซซ่า 400 G.', 'pr_name': 'CIRIO ซอสทำพิซซ่า 400 G.', 'pr_puqty': '12', 'pr_sa_method': '1', 'pr_sucode1': '2589      ', 'pr_suref3': 'C', 'prtype': 'I', 'psqty': '1', 'pstype': '1'}, {'cprcode': '0124461', 'iprcode': '0124461', 'oprcode': '0124461', 'ordertype': 'Y', 'pr_abb': 'NEW CHOICE LYCHEE', 'pr_active': 'Y', 'pr_cgcode': '02', 'pr_code': '0124461', 'pr_dpcode': '02', 'pr_engname': 'NEW CHOICE LYCHEE', 'pr_ggcode': '003', 'pr_market': 'NEW CHOICE กลิ่นลิ้นจี่', 'pr_name': 'NEW CHOICE กลิ่นลิ้นจี่', 'pr_puqty': '12', 'pr_sa_method': '1', 'pr_sucode1': '695       ', 'pr_suref3': 'A', 'prtype': 'I', 'psqty': '1', 'pstype': '1'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update with dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engname is JOHNNIE WALKER RED 70 CL.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'ProductDatabase' has no attribute 'updateWithDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c2a6bb676fa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m### update item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mupdatedItem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProductDatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdateWithDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'pr_engname'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'testName'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mupdatedItem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pr_engname'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'testName'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdatedItem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pr_engname'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ProductDatabase' has no attribute 'updateWithDict'"
     ]
    }
   ],
   "source": [
    "## get original item\n",
    "item = next(ProductDatabase.query('0000009'))\n",
    "print(f'engname is {item.data.get(\"pr_engname\")}')\n",
    "\n",
    "### update item\n",
    "updatedItem = ProductDatabase.updateWithDict(item,{'pr_engname':'testName'})\n",
    "assert updatedItem.data.get('pr_engname') == 'testName'\n",
    "print(updatedItem.data.get('pr_engname'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch load and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading hashkey allData-hash\n",
      "loaded hash is e706d6d6b6a9a7e831045ed1e859e7fb24bd5e4b\n",
      "data is still in sync, using local cache\n",
      "CPU times: user 284 ms, sys: 72.7 ms, total: 357 ms\n",
      "Wall time: 750 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = ProductDatabase.loadFromCache()\n",
    "assert data.shape[0] > 10000, 'loadFrom cache not working'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass_json\n",
    "@dataclass\n",
    "class ProductsFromList:\n",
    "  iprcodes: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lambdaProductsFromList(event, *args):\n",
    "  productsFromList = Event.parseDataClass(ProductsFromList,event)\n",
    "  result = ProductDatabase.productsFromList(productsFromList.iprcodes)\n",
    "  return Response.returnSuccess(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache exist\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'ProductDatabase' has no attribute 'loadHash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-c36516859f89>\u001b[0m in \u001b[0;36mlambdaProductsFromList\u001b[0;34m(event, *args)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlambdaProductsFromList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mproductsFromList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseDataClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mProductsFromList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProductDatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproductsFromList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproductsFromList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miprcodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturnSuccess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/.persisted_conda/python38/lib/python3.8/site-packages/nicHelper/wrappers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Note we are not binding func, but wrapper which accepts self but does exactly the same as func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/stacks/villaMaster/villa-master-dev/product/database2/villaProductDatabase/query.py\u001b[0m in \u001b[0;36mproductsFromList\u001b[0;34m(cls, iprcodes)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0madd_class_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQuerier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mproductsFromList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miprcodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0mdatabase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadFromS3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miprcode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miprcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miprcodes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0miprcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/.persisted_conda/python38/lib/python3.8/site-packages/nicHelper/wrappers.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Note we are not binding func, but wrapper which accepts self but does exactly the same as func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/stacks/villaMaster/villa-master-dev/product/database2/villaProductDatabase/s3.py\u001b[0m in \u001b[0;36mloadFromS3\u001b[0;34m(cls, bucketName, key, hashPath, cachePath, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashPath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcachePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cache exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mloadStringFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m       \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadDictFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcachePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'found a valid cache, using cache'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'ProductDatabase' has no attribute 'loadHash'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "event = Event.getInput({'iprcodes': ['0217153','203915','0000009']})\n",
    "response = lambdaProductsFromList(event)\n",
    "result = Response.parseBody(response)\n",
    "assert print(len(result)) == 3\n",
    "assert type(result[0])==dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump database to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resetS3Cache( bucketName= INVENTORY_BUCKET_NAME, key = 'allData', limit=500, **kwargs):\n",
    "  ''' upload changes to s3'''\n",
    "  ###### get all data\n",
    "#   allData = cls.loadFromS3(bucketName = bucketName, key = key, **kwargs)\n",
    "#   originalData = allData.copy()\n",
    "#   logging.debug(f'all data is {len(allData)}')\n",
    "\n",
    "  allData = {}\n",
    "  ##### get change list\n",
    "  changeList = list(ProductDatabase.scan())\n",
    "  print(f'{len(changeList)} changes to update')\n",
    "\n",
    "  ##### batch write\n",
    "  with ProductDatabase.batch_write() as batch:\n",
    "    for dbObject in changeList:\n",
    "      item = dbObject.data\n",
    "      # if product doesnt exist, create an empty dict\n",
    "      if not allData.get(item['iprcode']): allData[item['iprcode']] = {}\n",
    "      # if cprcode doesnt exist, create an empty dict\n",
    "      if not allData.get(item['iprcode']).get(item['cprcode']): allData[item['iprcode']][item['cprcode']] = {}\n",
    "      # update product\n",
    "      allData[item['iprcode']][item['cprcode']].update(item)\n",
    "      # set no change to all data after update\n",
    "\n",
    "  ####### update s3\n",
    "  ProductDatabase.saveAllS3(key = 'allData', \n",
    "                objectToSave = allData, \n",
    "                bucket = bucketName, **kwargs)\n",
    "    \n",
    "  print(f'alldata is {next(iter(allData.items()))}')\n",
    "  return allData\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# database = resetS3Cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@add_class_method(ProductDatabase)\n",
    "def dumpToS3(cls, bucketName= INVENTORY_BUCKET_NAME, key = 'allData', limit=500, **kwargs):\n",
    "  ''' upload changes to s3'''\n",
    "  ERRORITEMS = []\n",
    "  ###### get all data\n",
    "  allData = cls.loadFromS3(bucketName = bucketName, key = key, **kwargs)\n",
    "  originalData = allData.copy()\n",
    "  logging.debug(f'all data is {len(allData)}')\n",
    "\n",
    "  ##### get change list\n",
    "  changeList = list(cls.needsUpdateIndex.query(cls.TRUE, limit=limit))\n",
    "  logging.debug(f'{len(changeList)} changes to update')\n",
    "\n",
    "  ##### batch write\n",
    "  with cls.batch_write() as batch:\n",
    "    for dbObject in changeList:\n",
    "      item = dbObject.data\n",
    "      # if product doesnt exist, create an empty dict\n",
    "      if not allData.get(item['iprcode']): allData[item['iprcode']] = {}\n",
    "      # if cprcode doesnt exist, create an empty dict\n",
    "      if not allData.get(item['iprcode']).get(item['cprcode']): allData[item['iprcode']][item['cprcode']] = {}\n",
    "      # update product\n",
    "      allData[item['iprcode']][item['cprcode']].update(item)\n",
    "      # set no change to all data after update\n",
    "      try:\n",
    "        dbObject.setNoUpdate(batch=batch)\n",
    "      except:\n",
    "        ERRORITEMS.append(dbObject)\n",
    "\n",
    "  ####### update s3\n",
    "  if allData != originalData:\n",
    "    logging.debug(f'updating')\n",
    "    cls.saveAllS3(key = 'allData', \n",
    "                objectToSave = allData, \n",
    "                bucket = bucketName, **kwargs)\n",
    "    \n",
    "  else:\n",
    "    logging.debug('no changes to update')\n",
    "  logging.info(f'alldata is {next(iter(allData.items()))}')\n",
    "  if ERRORITEMS:\n",
    "    raise Exception(ERRORITEMS)\n",
    "    \n",
    "  #### if still not completed, trigger another loop####\n",
    "  if len(changeList) == limit:\n",
    "    print(f'not finished, doing the next batch of {limit}')\n",
    "    cls.dumpToS3(limit=limit)\n",
    "  return f\"saved {len(list(allData.keys()))} products\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache exist\n",
      "loading hashkey allData-hash\n",
      "loaded hash isPzfrumW4Vib/5yh3/4UtOHZI88U=\n",
      "found a valid cache, using cache\n",
      "not finished, doing the next batch of 500\n",
      "cache exist\n",
      "loading hashkey allData-hash\n",
      "loaded hash isPzfrumW4Vib/5yh3/4UtOHZI88U=\n",
      "found a valid cache, using cache\n",
      "CPU times: user 1.31 s, sys: 255 ms, total: 1.57 s\n",
      "Wall time: 2.74 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'saved 45149 products'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ProductDatabase.dumpToS3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lambdaDumpToS3(event, _):\n",
    "  try:\n",
    "    result = ProductDatabase.dumpToS3(limit=(os.environ.get('LIMIT') or 500))\n",
    "    ProductDatabase.notify(f'successfully executed dumpToS3 {result}')\n",
    "  except:\n",
    "    logging.exception('error dump to s3')\n",
    "    ProductDatabase.notify(f'error{errorString()}')\n",
    "    return Response.returnError(errorString())\n",
    "    \n",
    "  return Response.getReturn(body = {'result': result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache exist\n",
      "loading hashkey allData-hash\n",
      "loaded hash isPzfrumW4Vib/5yh3/4UtOHZI88U=\n",
      "found a valid cache, using cache\n",
      "saved 45149 products\n",
      "CPU times: user 625 ms, sys: 77.1 ms, total: 702 ms\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = Response.fromDict(lambdaDumpToS3('','')).body['result']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save using Standard (instant save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass_json(undefined=Undefined.INCLUDE)\n",
    "@dataclass\n",
    "class Product:\n",
    "  iprcode: str\n",
    "  cprcode: str\n",
    "  data: CatchAll\n",
    "@dataclass_json\n",
    "@dataclass\n",
    "class ValueUpdate:\n",
    "  items: List[Product]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def chunks(l, n): return [l[x: x+n] for x in range(0, len(l), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       " [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       " [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       " [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       " [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       " [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
       " [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
       " [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
       " [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks(list(range(100)),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@add_class_method(ProductDatabase)\n",
    "def valueUpdate(cls, inputs):\n",
    "    ''' \n",
    "      check for difference and batch update the changes in product data\n",
    "    '''\n",
    "    ### validate input\n",
    "    try:\n",
    "      validInputs = ValueUpdate.from_dict(inputs).to_dict().get('items')\n",
    "    except Exception as e:\n",
    "      raise KeyError(f'input failed validation {e}')\n",
    "      return\n",
    "    \n",
    "    itemsUpdated = {'success':0, 'failure': 0, 'skipped': 0 ,'failureMessage':[], 'timetaken(ms)': 0}\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    logging.info(f'there are {len(validInputs)} products to update')\n",
    "\n",
    "    ##### dividing input into batch of 500\n",
    "    inputBatches = chunks(validInputs, 500)\n",
    "    \n",
    "    for inputBatch in inputBatches:\n",
    "      with cls.batch_write() as batch:\n",
    "        # loop through each product\n",
    "        for input_ in inputBatch:\n",
    "          iprcode = input_['iprcode']\n",
    "          cprcode = input_['cprcode']\n",
    "\n",
    "          # check if product is in the database, if not, create an empty class with the product code\n",
    "          incumbentBr = next(cls.query(iprcode , cls.cprcode == cprcode), cls(iprcode = iprcode, cprcode = cprcode, data = {}))\n",
    "          # save original data to a variable\n",
    "          originalData = incumbentBr.data.copy()\n",
    "          # update data\n",
    "          updatedData = cls.updateWithDict(incumbentBr, input_)\n",
    "\n",
    "          logging.info(f'incumbentBr is {incumbentBr.iprcode}\\n, prcode is {iprcode}')\n",
    "\n",
    "          # check for difference\n",
    "          try:\n",
    "            if updatedData.data != originalData:\n",
    "              logging.info(f'product {iprcode} has changed from \\n{originalData} \\n{updatedData.data}')\n",
    "              batch.save(updatedData)\n",
    "              itemsUpdated['success'] += 1\n",
    "            else:\n",
    "              logging.info(f'no change for {iprcode}')\n",
    "              itemsUpdated['skipped'] += 1\n",
    "          except Exception as e:\n",
    "            itemsUpdated['failure'] += 1\n",
    "            itemsUpdated['failureMessage'].append(e)\n",
    "          \n",
    "        # log time taken\n",
    "        itemsUpdated['timetaken(ms)'] = (datetime.now()- t0).total_seconds()*1000\n",
    "    return itemsUpdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'items': [{'iprcode': '0171670',\n",
       "   'cprcode': '0171670',\n",
       "   'oprcode': '0171670',\n",
       "   'ordertype': 'Y',\n",
       "   'pr_abb': 'JIRAPAT YOUNG KALE 2',\n",
       "   'pr_active': 'Y',\n",
       "   'pr_cgcode': '05',\n",
       "   'pr_code': '0171670',\n",
       "   'pr_dpcode': '19',\n",
       "   'pr_engname': 'JIRAAT YOUNG KALE 200 G.',\n",
       "   'pr_ggcode': '057',\n",
       "   'pr_market': 'JIRAPAT ยอดคะน้า 200 G.',\n",
       "   'pr_name': 'JIRAPAT ยอดคะน้า 200 G.',\n",
       "   'pr_puqty': '1',\n",
       "   'pr_sa_method': '1',\n",
       "   'pr_sucode1': 'CM845',\n",
       "   'pr_suref3': 'A',\n",
       "   'prtype': 'I',\n",
       "   'psqty': '1',\n",
       "   'pstype': '1'}]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleProducts = [{ 'cprcode': '0171670', 'iprcode': '0171670', 'oprcode': '0171670', 'ordertype': 'Y', 'pr_abb': 'JIRAPAT YOUNG KALE 2', 'pr_active': 'Y', 'pr_cgcode': '05', 'pr_code': '0171670', 'pr_dpcode': '19', 'pr_engname': 'JIRAAT YOUNG KALE 200 G.', 'pr_ggcode': '057', 'pr_market': 'JIRAPAT ยอดคะน้า 200 G.', 'pr_name': 'JIRAPAT ยอดคะน้า 200 G.', 'pr_puqty': '1', 'pr_sa_method': '1', 'pr_sucode1': 'CM845', 'pr_suref3': 'A', 'prtype': 'I', 'psqty': '1', 'pstype': '1'}] #ProductDatabase.valueUpdate({'items':sampleProducts})\n",
    "ValueUpdate.from_dict({'items':sampleProducts}).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@add_class_method(ProductDatabase)\n",
    "def valueUpdate2(cls, inputs):\n",
    "    ''' \n",
    "      check for difference and batch update the changes in product data\n",
    "    '''\n",
    "    t0 = datetime.now()\n",
    "    ### validate input\n",
    "    try:\n",
    "      validInputs = ValueUpdate.from_dict(inputs).to_dict().get('items')\n",
    "    except Exception as e:\n",
    "      raise KeyError(f'input failed validation {e}')\n",
    "      return\n",
    "    \n",
    "    itemsUpdated = {'success':0, 'failure': 0, 'skipped': 0 ,'failureMessage':[], 'timetaken(ms)': 0}\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    logging.info(f'there are {len(validInputs)} products to update')\n",
    "\n",
    "    print(f'input validated {(datetime.now()-t0).total_seconds()*1000} ms')\n",
    "    ##### dividing input into batch of 500\n",
    "    inputBatches = chunks(validInputs, 500)\n",
    "    print(f'divided into chunks {(datetime.now()-t0).total_seconds()*1000} ms')\n",
    "    items = cls.loadFromS3()\n",
    "    print(f'get all from s3 {(datetime.now()-t0).total_seconds()*1000} ms')\n",
    "    \n",
    "    for inputBatch in inputBatches:\n",
    "      with cls.batch_write() as batch:\n",
    "        # loop through each product\n",
    "        for input_ in inputBatch:\n",
    "          iprcode = input_['iprcode']\n",
    "          cprcode = input_['cprcode']\n",
    "\n",
    "          # check if product is in the database, if not, create an empty class with the product code\n",
    "#           incumbentBr = next(cls.query(iprcode , cls.cprcode == cprcode), cls(iprcode = iprcode, cprcode = cprcode, data = {}))\n",
    "          incumbentBr = cls.fromDict(items.get(iprcode) or {'iprcode': iprcode, 'cprcode': cprcode})\n",
    "          # save original data to a variable\n",
    "          originalData = incumbentBr.data.copy()\n",
    "          # update data\n",
    "          updatedData = cls.updateWithDict(incumbentBr, input_)\n",
    "\n",
    "          logging.info(f'incumbentBr is {incumbentBr.iprcode}\\n, prcode is {iprcode}')\n",
    "\n",
    "          # check for difference\n",
    "          try:\n",
    "            if updatedData.data != originalData:\n",
    "              logging.info(f'product {iprcode} has changed from \\n{originalData} \\n{updatedData.data}')\n",
    "              batch.save(updatedData)\n",
    "              itemsUpdated['success'] += 1\n",
    "            else:\n",
    "              logging.info(f'no change for {iprcode}')\n",
    "              itemsUpdated['skipped'] += 1\n",
    "          except Exception as e:\n",
    "            itemsUpdated['failure'] += 1\n",
    "            itemsUpdated['failureMessage'].append(e)\n",
    "          \n",
    "        # log time taken\n",
    "        itemsUpdated['timetaken(ms)'] = (datetime.now()- t0).total_seconds()*1000\n",
    "    return itemsUpdated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProductDatabase.fromDict(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input validated 0.012 ms\n",
      "divided into chunks 0.5640000000000001 ms\n",
      "cache exist\n",
      "loading hashkey allData-hash\n",
      "loaded hash isPzfrumW4Vib/5yh3/4UtOHZI88U=\n",
      "found a valid cache, using cache\n",
      "get all from s3 982.624 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'success': 1,\n",
       " 'failure': 0,\n",
       " 'skipped': 0,\n",
       " 'failureMessage': [],\n",
       " 'timetaken(ms)': 982.977}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleProducts = [{ 'cprcode': '0171670', 'iprcode': '0171670', 'oprcode': '0171670', 'ordertype': 'Y', 'pr_abb': 'JIRAPAT YOUNG KALE 2', 'pr_active': 'Y', 'pr_cgcode': '05', 'pr_code': '0171670', 'pr_dpcode': '19', 'pr_engname': 'JIRAAT YOUNG KALE 200 G.', 'pr_ggcode': '057', 'pr_market': 'JIRAPAT ยอดคะน้า 200 G.', 'pr_name': 'JIRAPAT ยอดคะน้า 200 G.', 'pr_puqty': '1', 'pr_sa_method': '1', 'pr_sucode1': 'CM845', 'pr_suref3': 'A', 'prtype': 'I', 'psqty': '1', 'pstype': '1'}] #ProductDatabase.valueUpdate({'items':sampleProducts})\n",
    "products = ValueUpdate.from_dict({'items':sampleProducts}).to_dict()\n",
    "ProductDatabase.valueUpdate2(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lambdaUpdateProduct (event, _):\n",
    "  products = Event.parseBody(event)['products']\n",
    "  result = ProductDatabase.valueUpdate({'items':products})\n",
    "  return Response.getReturn(body = result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': '{\"success\":0,\"failure\":0,\"skipped\":1,\"failureMessage\":[],\"timetaken(ms)\":6.074999999999999}',\n",
       " 'statusCode': 200,\n",
       " 'headers': {'Access-Control-Allow-Headers': '*',\n",
       "  'Access-Control-Allow-Origin': '*',\n",
       "  'Access-Control-Allow-Methods': '*'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event = Event.getInput(body = {'products':sampleProducts})\n",
    "lambdaUpdateProduct(event, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save using s3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update using s3 link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@add_class_method(ProductDatabase)\n",
    "def updateS3Input(cls, inputBucketName = INPUT_BUCKET_NAME, key = '', **kwargs):\n",
    "  products = S3.load(key=key, bucket = inputBucketName,  **kwargs)\n",
    "  updateResult = cls.valueUpdate({'items':products})\n",
    "  return updateResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputKeyName = 'input-data-name'\n",
    "saveResult = S3.save(key=inputKeyName, \n",
    "                     objectToSave = sampleProducts , \n",
    "                     bucket = INPUT_BUCKET_NAME,\n",
    "                     accelerate = True)\n",
    "logging.info('test input data saved to s3')\n",
    "updateResult = ProductDatabase.updateS3Input( inputBucketName=INPUT_BUCKET_NAME, key= inputKeyName)\n",
    "\n",
    "logging.info(f's3 save result is {saveResult} update result is {updateResult}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lambdaUpdateS3(event, _):\n",
    "  inputKeyName = Event.from_dict(event).key()\n",
    "  try:\n",
    "    updateResult = ProductDatabase.updateS3Input(\n",
    "      inputBucketName=INPUT_BUCKET_NAME, key= inputKeyName)\n",
    "  except:\n",
    "    ProductDatabase.notify(f'error updating with s3 {errorString()}')\n",
    "    return Response.returnError(errorString())\n",
    "  \n",
    "  \n",
    "  \n",
    "  ProductDatabase.notify(f'success update {updateResult}')\n",
    "  return Response.getReturn(body = updateResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': '{\"success\":0,\"failure\":0,\"skipped\":1,\"failureMessage\":[],\"timetaken(ms)\":5.6129999999999995}',\n",
       " 'statusCode': 200,\n",
       " 'headers': {'Access-Control-Allow-Headers': '*',\n",
       "  'Access-Control-Allow-Origin': '*',\n",
       "  'Access-Control-Allow-Methods': '*'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputKeyName = 'input-data-name'\n",
    "saveResult = S3.save(key=inputKeyName, \n",
    "                     objectToSave = sampleProducts , \n",
    "                     bucket = INPUT_BUCKET_NAME)\n",
    "event = Event.getInput({'key': inputKeyName})\n",
    "lambdaUpdateS3(event, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleQueryInput = {\n",
    "    'iprcode': '0171670'\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product not found\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  print(ProductDatabase.singleProductQuery({'iprcode':'12345'}))\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0171670         {'cprcode': '0171670', 'iprcode': '0171670', '...\n",
       "iprcode                                                   0171670\n",
       "cprcode                                                   0171670\n",
       "oprcode                                                   0171670\n",
       "ordertype                                                       Y\n",
       "pr_abb                                       JIRAPAT YOUNG KALE 2\n",
       "pr_active                                                       Y\n",
       "pr_cgcode                                                      05\n",
       "pr_code                                                   0171670\n",
       "pr_dpcode                                                      19\n",
       "pr_engname                               JIRAAT YOUNG KALE 200 G.\n",
       "pr_ggcode                                                     057\n",
       "pr_market                                 JIRAPAT ยอดคะน้า 200 G.\n",
       "pr_name                                   JIRAPAT ยอดคะน้า 200 G.\n",
       "pr_puqty                                                        1\n",
       "pr_sa_method                                                    1\n",
       "pr_sucode1                                                  CM845\n",
       "pr_suref3                                                       A\n",
       "prtype                                                          I\n",
       "psqty                                                           1\n",
       "pstype                                                          1\n",
       "dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProductDatabase.singleProductQuery(sampleQueryInput).toSeries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lambdaSingleQuery(event, _):\n",
    "  key, value = Event.from_dict(event).firstKey()\n",
    "  try:\n",
    "    result = ProductDatabase.singleProductQuery({key:value}).data\n",
    "  except Exception as e:\n",
    "    return Response.returnError(f'{e}')\n",
    "  return Response.returnSuccess(body = result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': '{\"0171670\":{\"cprcode\":\"0171670\",\"iprcode\":\"0171670\",\"oprcode\":\"0171670\",\"ordertype\":\"Y\",\"pr_abb\":\"JIRAPAT YOUNG KALE 2\",\"pr_active\":\"Y\",\"pr_cgcode\":\"05\",\"pr_code\":\"0171670\",\"pr_dpcode\":\"19\",\"pr_engname\":\"JIRAPAT YOUNG KALE 200 G.\",\"pr_ggcode\":\"057\",\"pr_market\":\"JIRAPAT \\\\u0e22\\\\u0e2d\\\\u0e14\\\\u0e04\\\\u0e30\\\\u0e19\\\\u0e49\\\\u0e32 200 G.\",\"pr_name\":\"JIRAPAT \\\\u0e22\\\\u0e2d\\\\u0e14\\\\u0e04\\\\u0e30\\\\u0e19\\\\u0e49\\\\u0e32 200 G.\",\"pr_puqty\":\"1.00\",\"pr_sa_method\":\"1\",\"pr_sucode1\":\"CM845\",\"pr_suref3\":\"A\",\"prtype\":\"I\",\"psqty\":\"1\",\"pstype\":\"1\",\"pr_country_th\":\"none\",\"pr_country_en\":\"none\",\"pr_keyword_th\":\"none\",\"pr_keyword_en\":\"none\",\"pr_filter_th\":\"none\",\"pr_filter_en\":\"none\",\"online_category_l1_th\":\"none\",\"online_category_l1_en\":\"none\",\"online_category_l2_th\":\"none\",\"online_category_l2_en\":\"none\",\"online_category_l3_th\":\"none\",\"online_category_l3_en\":\"none\",\"content_en\":\"0171670 JIRAPAT YOUNG KALE 200 G.\",\"content_th\":\"JIRAPAT YOUNG KALE 200 G.\",\"hema_brand_th\":\"none\",\"hema_brand_en\":\"none\",\"hema_sizedesc\":\"none\"},\"iprcode\":\"0171670\",\"cprcode\":\"0171670\",\"oprcode\":\"0171670\",\"ordertype\":\"Y\",\"pr_abb\":\"JIRAPAT YOUNG KALE 2\",\"pr_active\":\"Y\",\"pr_cgcode\":\"05\",\"pr_code\":\"0171670\",\"pr_dpcode\":\"19\",\"pr_engname\":\"JIRAAT YOUNG KALE 200 G.\",\"pr_ggcode\":\"057\",\"pr_market\":\"JIRAPAT \\\\u0e22\\\\u0e2d\\\\u0e14\\\\u0e04\\\\u0e30\\\\u0e19\\\\u0e49\\\\u0e32 200 G.\",\"pr_name\":\"JIRAPAT \\\\u0e22\\\\u0e2d\\\\u0e14\\\\u0e04\\\\u0e30\\\\u0e19\\\\u0e49\\\\u0e32 200 G.\",\"pr_puqty\":\"1\",\"pr_sa_method\":\"1\",\"pr_sucode1\":\"CM845\",\"pr_suref3\":\"A\",\"prtype\":\"I\",\"psqty\":\"1\",\"pstype\":\"1\"}',\n",
       " 'statusCode': 200,\n",
       " 'headers': {'Access-Control-Allow-Headers': '*',\n",
       "  'Access-Control-Allow-Origin': '*',\n",
       "  'Access-Control-Allow-Methods': '*'}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event = Event(body = json.dumps(sampleQueryInput)).to_dict()\n",
    "lambdaSingleQuery(event,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': 'product not found'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = lambdaSingleQuery(Event.getInput({'iprcode':'11234'}),'')\n",
    "Response.parseBody(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AllQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product-bucket-dev-manual\n",
      "https://product-bucket-dev-manual.s3-accelerate.amazonaws.com/allData?AWSAccessKeyId=AKIAVX4Z5TKDSNNNULGB&Signature=JlQUPmevbHN%2BWsh0kHmq16MbDV8%3D&Expires=1608532515\n",
      "received 73095 results, the first one is ('0217153', {'0217153': {'cprcode': '0217153', 'iprcode': '0217153', 'oprcode': '0217153', 'ordertype': 'Y', 'pr_abb': 'COCOA LOCO MILK CHOC', 'pr_active': 'Y', 'pr_cgcode': '98', 'pr_code': '0217153', 'pr_dpcode': '28', 'pr_engname': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_ggcode': '003', 'pr_market': 'COCOA LOCO MILK CHOCOLATE OWL', 'pr_name': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_puqty': '24', 'pr_sa_method': '1', 'pr_sucode1': 'F1222', 'pr_suref3': 'S', 'prtype': 'I', 'psqty': '1', 'pstype': '1', 'pr_country_th': '', 'pr_country_en': 'United Kingdom', 'pr_keyword_th': '', 'pr_keyword_en': '', 'pr_filter_th': '', 'pr_filter_en': '', 'online_category_l1_th': '', 'online_category_l1_en': '', 'online_category_l2_th': '', 'online_category_l2_en': '', 'online_category_l3_th': '', 'online_category_l3_en': '', 'villa_category_l1_en': 'Dry Grocery', 'villa_category_l2_en': 'Grocery', 'villa_category_l3_en': 'Cookies & Snacks', 'villa_category_l4_en': 'Biscuits & Crackers', 'content_en': '0217153 COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'content_th': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'hema_brand_th': '', 'hema_brand_en': '', 'hema_sizedesc': '', 'pr_brand_en': '', 'pr_brand_th': '', 'pr_online_name_en': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_online_name_th': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'hema_name_en': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'hema_name_th': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_name_en': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_name_th': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_barcode': '5060148383378', 'pr_barcode2': '506014838337', 'sort_weight': '0'}})\n"
     ]
    }
   ],
   "source": [
    "from s3bz.s3bz import Requests\n",
    "url = ProductDatabase.allQuery(bucket = INVENTORY_BUCKET_NAME, key='allData')\n",
    "print(url)\n",
    "# response = requests.get(url)\n",
    "result = Requests.getContentFromUrl(url)\n",
    "print(f'received {len(list(result.keys()))} results, the first one is {next(iter(result.items()))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lambdaAllQuery(event, _):\n",
    "  url = ProductDatabase.allQuery(bucket = INVENTORY_BUCKET_NAME, key='allData')\n",
    "  return Response.getReturn(body = {'url': url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product-bucket-dev-manual\n",
      "received 73095 results, the first one is ('0217153', {'0217153': {'cprcode': '0217153', 'iprcode': '0217153', 'oprcode': '0217153', 'ordertype': 'Y', 'pr_abb': 'COCOA LOCO MILK CHOC', 'pr_active': 'Y', 'pr_cgcode': '98', 'pr_code': '0217153', 'pr_dpcode': '28', 'pr_engname': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_ggcode': '003', 'pr_market': 'COCOA LOCO MILK CHOCOLATE OWL', 'pr_name': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_puqty': '24', 'pr_sa_method': '1', 'pr_sucode1': 'F1222', 'pr_suref3': 'S', 'prtype': 'I', 'psqty': '1', 'pstype': '1', 'pr_country_th': '', 'pr_country_en': 'United Kingdom', 'pr_keyword_th': '', 'pr_keyword_en': '', 'pr_filter_th': '', 'pr_filter_en': '', 'online_category_l1_th': '', 'online_category_l1_en': '', 'online_category_l2_th': '', 'online_category_l2_en': '', 'online_category_l3_th': '', 'online_category_l3_en': '', 'villa_category_l1_en': 'Dry Grocery', 'villa_category_l2_en': 'Grocery', 'villa_category_l3_en': 'Cookies & Snacks', 'villa_category_l4_en': 'Biscuits & Crackers', 'content_en': '0217153 COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'content_th': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'hema_brand_th': '', 'hema_brand_en': '', 'hema_sizedesc': '', 'pr_brand_en': '', 'pr_brand_th': '', 'pr_online_name_en': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_online_name_th': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'hema_name_en': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'hema_name_th': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_name_en': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_name_th': 'COCOA LOCO MILK CHOCOLATE OWL LOLLY 26G.', 'pr_barcode': '5060148383378', 'pr_barcode2': '506014838337', 'sort_weight': '0'}})\n",
      "CPU times: user 6.72 s, sys: 339 ms, total: 7.06 s\n",
      "Wall time: 7.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from s3bz.s3bz import Requests\n",
    "url = Response.fromDict(lambdaAllQuery('', '')).body['url']\n",
    "result = Requests.getContentFromUrl(url)\n",
    "print(f'received {len(list(result.keys()))} results, the first one is {next(iter(result.items()))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update s3, checking scan time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking scan time\n",
      "CPU times: user 16.2 s, sys: 915 ms, total: 17.2 s\n",
      "Wall time: 29.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "106219"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print('checking scan time')\n",
    "len(list(ProductDatabase.scan()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
